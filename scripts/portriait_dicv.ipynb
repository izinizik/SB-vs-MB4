{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427255d-97c6-4825-91c0-115b5870110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/labneuro2/.local/lib/python3.12/site-packages/network-portrait-divergence\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import networkx as nx\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from portrait_divergence import portrait_divergence_weighted\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd2cfa-e3b2-44d3-bd11-efbedd80f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data\n",
    "data_path = \"/Users/labneuro2/Documents/lab/SBvsMB4/halfpipe\"\n",
    "atlases_path = \"/Users/labneuro2/Documents/lab/SBvsMB4/atlases\"\n",
    "\n",
    "# Atlas variants to process\n",
    "atlas_variants = ['100Parcels_S1', '200Parcels_S2', '400Parcels_S4']\n",
    "\n",
    "# Threshold for bad BOLD signal\n",
    "bold_threshold = 0.8\n",
    "\n",
    "df = pd.read_csv('dof_summary.csv', sep=';')\n",
    "\n",
    "# Extract subject/session/task info\n",
    "df['subject'] = df['file'].str.extract(r'(sub-\\d+)_')[0]\n",
    "df['session'] = df['file'].str.extract(r'(ses-\\d+)_')[0]\n",
    "df['task'] = df['file'].str.extract(r'task-([A-Za-z0-9]+)_')[0]\n",
    "\n",
    "df_unique = df[['subject', 'session', 'task']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896703a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atlas_labels(atlas_labels_file):\n",
    "    with open(atlas_labels_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    labels = []\n",
    "    for i in range(0, len(lines), 2):\n",
    "        name = lines[i].strip()\n",
    "        values = list(map(int, lines[i+1].strip().split()))\n",
    "        labels.append([name] + values)\n",
    "    return pd.DataFrame(labels, columns=['name', 'index', 'R', 'G', 'B', 'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac344dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in atlas_variants:\n",
    "    parcels, tian = variant.split(\"_\")\n",
    "    print(f\"\\nüîç Processing atlas: {variant}\")\n",
    "\n",
    "    atlas_filename = f\"{atlases_path}/Schaefer2018_{parcels}_7Networks_order_Tian_Subcortex_{tian}_3T_MNI152NLin2009cAsym_2mm.nii.gz\"\n",
    "    atlas_labels_file = f'{atlases_path}/Schaefer2018_{parcels}_7Networks_order_Tian_Subcortex_{tian}_label.txt'\n",
    "    \n",
    "    atlas_labels = load_atlas_labels(atlas_labels_file)\n",
    "    all_rois = set(atlas_labels['index'])\n",
    "    \n",
    "    masker = NiftiLabelsMasker(atlas_filename, standardize=False)\n",
    "\n",
    "    global_bad_rois = set()\n",
    "    \n",
    "    # Iterate over all unique subject/session/task combinations\n",
    "    for _, row in df_unique.iterrows():\n",
    "        subject = row['subject']\n",
    "        session = row['session']\n",
    "        task = row['task']\n",
    "        \n",
    "        bold_path = f'{data_path}/{subject}/{session}/func/{subject}_{session}_task-{task}_setting-preproc_desc-brain_mask.nii.gz'\n",
    "        if not os.path.exists(bold_path):\n",
    "            print(f\"‚ö†Ô∏è Missing file: {bold_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Extract time series for each ROI\n",
    "            time_series = masker.fit_transform(nib.load(bold_path))\n",
    "            # Mark ROIs as bad if their minimum signal is below threshold\n",
    "            bad_rois = {i for i in range(time_series.shape[1]) if np.min(time_series[:, i]) < bold_threshold}\n",
    "            global_bad_rois.update(bad_rois)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to process {bold_path}: {e}\")\n",
    "\n",
    "    good_rois = sorted(list(all_rois - global_bad_rois))\n",
    "    bad_rois = sorted(list(global_bad_rois))\n",
    "\n",
    "    # Save good and bad ROI indices to text files\n",
    "    with open(f'good_rois_{variant}11.txt', 'w') as f:\n",
    "        f.write('\\n'.join(map(str, good_rois)))\n",
    "\n",
    "    print(f\"‚úÖ Saved: {len(good_rois)} good and {len(bad_rois)} bad ROIs for {variant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce757e8-7237-41b3-8c20-2e65ddef8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_to_graph(matrix, selected_rois, good_rois, threshold=0.2):\n",
    "    import networkx as nx\n",
    "    G = nx.Graph()\n",
    "    filtered_rois = sorted(set(good_rois).intersection(selected_rois))\n",
    "    matrix = matrix[np.ix_(filtered_rois, filtered_rois)]\n",
    "    edges = []\n",
    "\n",
    "    for idx_i, i in enumerate(filtered_rois):\n",
    "        for idx_j, j in enumerate(filtered_rois):\n",
    "            if idx_j > idx_i:\n",
    "                weight = matrix[idx_i, idx_j]\n",
    "                if weight > 0:\n",
    "                    edges.append((i, j, weight))\n",
    "\n",
    "    edges = sorted(edges, key=lambda x: abs(x[2]), reverse=True)\n",
    "    top_percent = int(len(edges) * threshold)\n",
    "    edges = edges[:top_percent]\n",
    "\n",
    "    for i, j, weight in edges:\n",
    "        G.add_edge(i, j, weight=weight)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7e13f-c95d-4777-b0ed-2a652fb02d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_portrait_divergence_analysis(\n",
    "    atlas_variant=\"400_S4\", \n",
    "    fd_threshold = 0.4,\n",
    "    min_dof=15,\n",
    "    roi_type=\"cortical\", \n",
    "    trimmed_range=range(5, 14),\n",
    "):\n",
    "    \n",
    "    parcels, tian = atlas_variant.split(\"_\")\n",
    "    atlas_prefix = f\"schaefer_{parcels}_Tian_{tian}\"\n",
    "\n",
    "    fd_label = f\"fd_{int(fd_threshold * 1000):03d}\"\n",
    "    base_path = f\"{correlation_matrices_path}/{atlas_prefix}_{fd_label}\"\n",
    "\n",
    "    good_rois = np.loadtxt(f\"good_rois_{atlas_variant}.txt\", dtype=int)\n",
    "\n",
    "    # Wczytaj etykiety\n",
    "    atlas_labels_file = f\"{atlases_path}/Schaefer2018_{parcels}_7Networks_order_Tian_Subcortex_{tian}_label.txt\"\n",
    "    atlas_labels = load_atlas_labels(atlas_labels_file)\n",
    "\n",
    "    if roi_type == \"cortical\":\n",
    "        selected_rois = set(atlas_labels[atlas_labels['name'].str.contains(\"Networks\")]['index']-1)\n",
    "    else:\n",
    "        selected_rois = set(atlas_labels['index']-1)\n",
    "        \n",
    "    df_filtered = df[df['fd_threshold'] == fd_threshold].copy()\n",
    "    df_filtered = df_filtered.dropna(subset=['afni_dof'])\n",
    "\n",
    "\n",
    "    all_divergence_results = []\n",
    "\n",
    "    for trimmed in trimmed_range:\n",
    "        for method in [\"SB\", \"MB4\"]:\n",
    "            subject_sessions = {}\n",
    "            for subject in df_filtered['subject'].unique():\n",
    "                sub_df = df_filtered[(df_filtered['subject'] == subject) & (df_filtered['task'] == method)]\n",
    "                ses1 = sub_df[sub_df['session'] == 'ses-1']\n",
    "                ses2 = sub_df[sub_df['session'] == 'ses-2']\n",
    "                \n",
    "                ses1_match = ses1[ses1['minutes'] == trimmed]\n",
    "                ses2_match = ses2[ses2['minutes'] == trimmed]\n",
    "\n",
    "                if not ses1_match.empty and not ses2_match.empty:\n",
    "                    dof1 = ses1_match.iloc[0]['afni_dof']\n",
    "                    dof2 = ses2_match.iloc[0]['afni_dof']\n",
    "                    if dof1 >= min_dof and dof2 >= min_dof:\n",
    "                        file1 = f\"{base_path}/{subject}_ses-1_task-{method}_trimmed_{trimmed}min_correlation.csv\"\n",
    "                        file2 = f\"{base_path}/{subject}_ses-2_task-{method}_trimmed_{trimmed}min_correlation.csv\" \n",
    "                        if os.path.exists(file1) and os.path.exists(file2):\n",
    "                            subject_sessions[subject] = (file1, file2)\n",
    "            def compute_subject_divergence(subject, f1, f2, trimmed, method, selected_rois, good_rois):\n",
    "                try:\n",
    "                    matrix1 = np.loadtxt(f1, delimiter=',')\n",
    "                    matrix2 = np.loadtxt(f2, delimiter=',')\n",
    "                    G1 = correlation_matrix_to_graph(matrix1, selected_rois, good_rois)\n",
    "                    G2 = correlation_matrix_to_graph(matrix2, selected_rois, good_rois)\n",
    "                    div = portrait_divergence_weighted(G1, G2)\n",
    "                    return (trimmed, subject, div, method)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è B≈ÇƒÖd dla {subject}: {e}\")\n",
    "                    return None\n",
    "            \n",
    "            results = Parallel(n_jobs=5)(\n",
    "                delayed(compute_subject_divergence)(subject, f1, f2, trimmed, method, selected_rois, good_rois)\n",
    "                for subject, (f1, f2) in subject_sessions.items()\n",
    "            )\n",
    "            \n",
    "            divergence_results = [r for r in results if r is not None]\n",
    "            all_divergence_results.extend(divergence_results)\n",
    "\n",
    "    df_results = pd.DataFrame(all_divergence_results, columns=[\"Trimmed\", \"Subject\", \"Divergence\", \"Method\"])\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4dea3-2e38-4088-9975-3d1efb2f7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrices_path = '/Users/labneuro2/Documents/lab/SBvsMB4/correlation_matrices'\n",
    "\n",
    "# Option lists\n",
    "roi_types = [\"cortical\", \"all\"]\n",
    "fd_thresholds = [0.4, 1.0]\n",
    "\n",
    "# Output Excel file path\n",
    "output_excel = \"portriat_divergence_results.xlsx\"\n",
    "\n",
    "# Use a single ExcelWriter for all results\n",
    "with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "    for atlas_variant in atlas_variants:\n",
    "        schaefer = atlas_variant.split(\"_\")[0][:-7]\n",
    "        tian = atlas_variant.split(\"_\")[1]\n",
    "        for fd_threshold in fd_thresholds:\n",
    "            for roi_type in roi_types:\n",
    "                if roi_type == \"cortical\":  \n",
    "                    sheet_name = f\"Schaefer{schaefer}_fd_{fd_threshold}\"\n",
    "                else:\n",
    "                    sheet_name = f\"Schaefer{schaefer}_Tian{tian}_fd_{fd_threshold}\"\n",
    "                print(f\"\\n Analysing: {atlas_variant} | {fd_threshold} | {roi_type}\")\n",
    "                try:\n",
    "                    # Run the analysis\n",
    "                    df_results = run_portrait_divergence_analysis(\n",
    "                        atlas_variant=atlas_variant,\n",
    "                        fd_threshold=fd_threshold,\n",
    "                        min_dof=15,\n",
    "                        roi_type=roi_type,\n",
    "                        trimmed_range=range(5, 14)\n",
    "                    )\n",
    "\n",
    "                    # Save results to Excel sheet\n",
    "                    df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error {atlas_variant} + {fd_threshold} + {roi_type}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All analyses completed and Excel file saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
